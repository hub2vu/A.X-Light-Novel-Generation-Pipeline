import os
import json
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# === ì„¤ì • ===
input_folder = "./texts"
output_folder = "./output_json"
os.makedirs(output_folder, exist_ok=True)

# ëª¨ë¸ ë¡œë“œ
model_name = "skt/A.X-4.0-Light"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

# === í•­ëª©ë³„ í”„ë¡¬í”„íŠ¸ ===
def create_prompt(text, info_type):
    if info_type == "OUTLINE":
        instruction = "ë‹¤ìŒ ì†Œì„¤ ì›ë¬¸ì—ì„œ ì¤‘ì‹¬ ì‚¬ê±´ì´ë‚˜ ì¤„ê±°ë¦¬ë¥¼ ëª…í™•íˆ ìš”ì•½í•œ ì•„ì›ƒë¼ì¸ì„ 3~4 ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì¤˜."
    elif info_type == "CHARACTERS":
        system_prompt = (
            "ë„ˆëŠ” ì†Œì„¤ ì›ë¬¸ì—ì„œ ë“±ì¥ì¸ë¬¼ë“¤ì˜ ì´ë¦„ê³¼ ê° ì¸ë¬¼ì˜ ì—­í• ì„ ê°„ëµíˆ ì •ë¦¬í•´ì£¼ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. "
            "ê° ì¸ë¬¼ì˜ ì—­í• ì„ 2~3 ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•´."
        )
        user_prompt = f"ë‹¤ìŒ ì†Œì„¤ ì›ë¬¸ì—ì„œ ë“±ì¥í•˜ëŠ” ì¸ë¬¼ë“¤ê³¼ ê° ì¸ë¬¼ì˜ ê°„ëµí•œ ì—­í• ì„ ì‘ì„±í•´ì¤˜.\n\n[ì†Œì„¤ ì›ë¬¸]\n{text}\n\n[CHARACTERS]\n"

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        return messages  # charactersëŠ” messages í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    elif info_type == "SETTING":
        instruction = "ë‹¤ìŒ íŒíƒ€ì§€ ì†Œì„¤ ì›ë¬¸ì—ì„œ ì‹œëŒ€ì  ë°°ê²½ê³¼ ê³µê°„ì  ë°°ê²½ì„ 2~3 ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì¤˜."
    else:
        raise ValueError("ì˜ëª»ëœ info_typeì…ë‹ˆë‹¤.")

    prompt = f"{instruction}\n\n[ì†Œì„¤ ì›ë¬¸]\n{text}\n\n[{info_type}]\n"
    return prompt

# === ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜ ===
def generate_info(text, info_type, max_tokens=512):
    prompt = create_prompt(text, info_type)

    if info_type == "CHARACTERS":
        # apply_chat_template â†’ chat ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
        input_ids = tokenizer.apply_chat_template(
            prompt,
            add_generation_prompt=True,
            return_tensors="pt"
        ).to(model.device)
        # â¬‡ï¸ attention mask ëª…ì‹œì ìœ¼ë¡œ ìƒì„±
        attention_mask = (input_ids != tokenizer.pad_token_id).long()
        inputs = {
            "input_ids": input_ids,
            "attention_mask": attention_mask
        }  # dict í˜•íƒœë¡œ ë³€í™˜
    else:
        # ì¼ë°˜ í…ìŠ¤íŠ¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    outputs = model.generate(
        **inputs,
        max_new_tokens=max_tokens,
        temperature=0.4,
        top_p=0.9,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id
    )

    result = tokenizer.decode(
        outputs[0][inputs["input_ids"].shape[-1]:],
        skip_special_tokens=True
    ).strip()

    return result

# === JSON ìƒì„± ===
def make_json(original_text, outline, characters, setting):
    return {
        "messages": [
            {
                "role": "system",
                "content": "ë„ˆëŠ” ì•„ì›ƒë¼ì¸ê³¼ ìºë¦­í„° ë° ì„¸ê³„ê´€ ì •ë³´ì— ë”°ë¼, í•œêµ­ì–´ ì†Œì„¤ ì›ë¬¸ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ ì¨ì£¼ëŠ” ì†Œì„¤ ìƒì„± ì¸ê³µì§€ëŠ¥ì´ë‹¤. ë¬¸ì²´ëŠ” ìì—°ìŠ¤ëŸ½ê³  ì‹œëŒ€ì  ë°°ê²½ì— ë§ê²Œ ì“´ë‹¤."
            },
            {
                "role": "user",
                "content": f"[OUTLINE] {outline}\n[CHARACTERS] {characters}\n[SETTING] {setting}"
            },
            {
                "role": "assistant",
                "content": original_text
            }
        ]
    }


# === ì „ì²´ ì²˜ë¦¬ ë£¨í”„ ===
for filename in os.listdir(input_folder):
    if filename.lower().endswith(".txt"):
        input_path = os.path.join(input_folder, filename)
        output_path = os.path.join(output_folder, filename.replace(".txt", ".json"))

        # ì›ë³¸ ì†Œì„¤ ë¡œë“œ
        with open(input_path, encoding="utf-8") as f:
            original_text = f.read().strip()

        print(f"\nğŸ” {filename} ì²˜ë¦¬ ì‹œì‘...")

        # ê° í•­ëª©ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ ìƒì„±
        print("ğŸ“Œ Outline ìƒì„± ì¤‘...")
        outline = generate_info(original_text, "OUTLINE")

        print("ğŸ“Œ Characters ìƒì„± ì¤‘...")
        characters = generate_info(original_text, "CHARACTERS", max_tokens=300)

        print("ğŸ“Œ Setting ìƒì„± ì¤‘...")
        setting = generate_info(original_text, "SETTING")

        # JSON ìƒì„± ë° ì €ì¥
        json_data = make_json(original_text, outline, characters, setting)
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=4)

        print(f"âœ… {filename} â†’ {output_path} ì €ì¥ ì™„ë£Œ.")

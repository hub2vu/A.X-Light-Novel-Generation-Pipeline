import os
import re
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# === ì„¤ì • ===
base_model_name = "skt/A.X-4.0-Light"
story_file = "../new_story_edited.txt"
relation_file = "../rag_corpus/relation.txt"
character_file = "../rag_corpus/character.txt"
relation_update_file = "./rag_corpus/relation_update.txt"

# === character.txtì—ì„œ ì´ë¦„ ì¶”ì¶œ ===
def extract_character_names(path):
    with open(path, encoding="utf-8") as f:
        lines = f.readlines()
    names = []
    for line in lines:
        match = re.match(r"^\d+\.\s*(\S+)", line.strip())
        if match:
            names.append(match.group(1))
    return names

character_list = extract_character_names(character_file)

# === ëª¨ë¸ ë¡œë”© ===
tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_fast=False)
model = AutoModelForCausalLM.from_pretrained(base_model_name, device_map="auto", torch_dtype=torch.bfloat16)
model.eval()

# === ì†Œì„¤ ë¶ˆëŸ¬ì˜¤ê¸° ===
with open(story_file, encoding="utf-8") as f:
    story_text = f.read()

# === í”„ë¡¬í”„íŠ¸ êµ¬ì„± ===
system_prompt = "ë„ˆëŠ” ì¶”ë¦¬ì†Œì„¤ ë¶„ì„ê°€ì•¼. ì£¼ì–´ì§„ ì†Œì„¤ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë“±ì¥ì¸ë¬¼ ê°„ì˜ ê´€ê³„ ë³€í™”ë¥¼ ë¶„ì„í•´."
prompt = f"""
[SYSTEM]
{system_prompt}

[USER]
ë‹¤ìŒì€ ì´ë²ˆ í™” ì†Œì„¤ ë‚´ìš©ì´ì•¼. ë“±ì¥ì¸ë¬¼ì€ {', '.join(character_list)} ì´ê³ , ë“±ì¥ì¸ë¬¼ ê°„ì˜ ê´€ê³„ ë³€í™”ê°€ ìˆìœ¼ë©´ ìš”ì•½í•´ì¤˜.
ê¸°ì¡´ì— ì—†ë˜ ê´€ê³„ê°€ ìƒˆë¡œ ë“œëŸ¬ë‚˜ê±°ë‚˜, ê°ˆë“±/í˜‘ë ¥ì´ ìƒê¸´ ê²½ìš° êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•´ì¤˜. í˜•ì‹ì€ "A - B: ê´€ê³„ë‚´ìš©" í˜•íƒœë¡œ ì¨ì¤˜.

[STORY]
{story_text}
"""

# === ëª¨ë¸ ì…ë ¥ ===
input_ids = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=2048).to(model.device)

# === ìƒì„± ===
with torch.no_grad():
    output = model.generate(
        input_ids.input_ids,
        max_new_tokens=512,
        temperature=0.7,
        top_p=0.95
    )

generated = tokenizer.decode(output[0][input_ids.input_ids.shape[1]:], skip_special_tokens=True)
print("ğŸ” ì¶”ì¶œëœ ê´€ê³„ ë³€í™” [ìµœì´ˆìƒì„±]:\n", generated.strip())

# === ê´€ê³„ ì—†ëŠ” ë‚´ìš© ì œê±° ==
def filter_meaningful_relations(text):
    lines = text.strip().split("\n")
    filtered = []
    for line in lines:
        if any(kw in line for kw in ["ë‘ ì¸ë¬¼ ê°„ì˜ ê´€ê³„ ë³€í™”ë¥¼ ì¶”ë¡ í•˜ê¸° ì–´ë µë‹¤"]):
            continue
        if "-" in line and ":" in line:
            filtered.append(line.strip())
    return "\n".join(filtered)

filtered_generated = filter_meaningful_relations(generated)
print("ğŸ” ì¶”ì¶œëœ ê´€ê³„ ë³€í™” [ë¬´ê´€ê³„í•„í„°]:\n", filtered_generated.strip())

# === ê´€ê³„ ë³€í™” ì €ì¥ (ì´ë¦„ìˆœ ì •ë ¬ ì ìš©) ===
with open(relation_update_file, "w", encoding="utf-8") as f:
    for line in filtered_generated.strip().split("\n"):
        line = line.strip()
        match = re.match(r"^(\S+)\s*-\s*(\S+)\s*:\s*(.+)", line)
        if match:
            char1, char2, desc = match.groups()
            char1, char2 = sorted([char1, char2])  # ì´ë¦„ ìˆœ ì •ë ¬
            f.write(f"{char1} - {char2}: {desc.strip()}\n")


print(f"âœ… ìƒˆë¡œìš´ ê´€ê³„ ë³€í™” ì €ì¥ ì™„ë£Œ â†’ {relation_update_file}")
